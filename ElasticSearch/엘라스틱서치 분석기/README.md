# 엘라스틱서치 분석기

## 텍스트 분석 개요

 엘라스틱서치는 루씬을 기반으로 구축된 텍스트 기반 검색엔진입니다. 루씬은 내부적으로 다양한 분석기를 제공하는데, 엘라스틱서치는 루씬이 제공하는 분석기를 그대로 활용합니다.

 다음과 같은 문장이 있다고 해보겠습니다.

"프로그래밍하기 좋은 날씨, 즐거운 프로그래밍"

 일반적으로 특정 단어가 포함된 문서를 찾으려면 검색어로 찾을 단어를 입력하면 될 것이라 생각할 것입니다. 하지만 엘라스틱 서치는 텍스트를 처리하기 위해 기본적으로 분석기를 사용하기 때문에 생각하는대로 동작하지 않습니다. 예를 들어 "프로그래밍"이라는 단어를 입력하면 검색되지 않을 것입니다. 이는 "프로그래밍"이라는 단어가 존재하지 않기 때문에 해당 문서가 검색되지 않는 것입니다.

** 엘라스틱서치는 문서를 색인하기 전에 해당 문서의 필드 타입이 무엇인지 확인하고 텍스트 타입이면 분석기를 이용해 이를 분석합니다. 텍스트가 분석되면 개별 텀(term)으로 나뉘어 형태소 형태로 분석됩니다. 해당 형태소는 특정 원칙에 의해 필터링되어 단어가 삭제되거나 추가, 수정되고 최종적으로 역색인 됩니다.**

 아까 위에서 예를 들었던 "프로그래밍하기 좋은 날씨, 즐거운 프로그래밍"이라는 문장이 실제로 어떻게 분석되는지 확인해 보겠습니다.

```
POST _analyze
{
  "analyzer": "standard",
  "text": "프로그래밍하기 좋은 날씨, 즐거운 프로그래밍"
}
```

 위의 분석 결과는 아래와 같이 token 값으로 표시됩니다.

```
{
  "tokens" : [
    {
      "token" : "프로그래밍하기",
      "start_offset" : 0,
      "end_offset" : 7,
      "type" : "<HANGUL>",
      "position" : 0
    },
    {
      "token" : "좋은",
      "start_offset" : 8,
      "end_offset" : 10,
      "type" : "<HANGUL>",
      "position" : 1
    },
    {
      "token" : "날씨",
      "start_offset" : 11,
      "end_offset" : 13,
      "type" : "<HANGUL>",
      "position" : 2
    },
    {
      "token" : "즐거운",
      "start_offset" : 15,
      "end_offset" : 18,
      "type" : "<HANGUL>",
      "position" : 3
    },
    {
      "token" : "프로그래밍",
      "start_offset" : 19,
      "end_offset" : 24,
      "type" : "<HANGUL>",
      "position" : 4
    }
  ]
}
```

 예제에서는 특별한 분석기 없이 Standard Analyzer를 사용했기 때문에 별도의 형태소 분석은 이루어지지 않았습니다. 텍스트를 분석할 때 별도의 분석기를 지정하지 않으면 기본적으로 Standard Analyzer가 사용됩니다.


---

## 참고자료

[엘라스틱서치 실무 가이드](http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode=9791158391485&orderClick=LEa&Kc=) <<권택환, 김동우, 김흥래, 박진현, 최용호, 황희정 지음>>